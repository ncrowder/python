{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5fc7c05",
   "metadata": {},
   "source": [
    "# Hands-On Lab 2 - Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa0850",
   "metadata": {},
   "source": [
    "### Step 1 - Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d438e",
   "metadata": {},
   "source": [
    "The *adult_train.csv* file is the training dataset. Run the following code cell to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198550af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_train = pd.read_csv('adult_train.csv')\n",
    "adult_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1a90e",
   "metadata": {},
   "source": [
    "### Step 2 - Prepare the Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa77a4",
   "metadata": {},
   "source": [
    "As you learned in Lab 1, you must always prepare your data before training a machine learning model. For this lab, we will expand the working hypotheses to include the *Race*, *CapitalGain*, and *CapitalLoss* features. The intuition is that *Race* is associated with income in the US economy, and the *CapitalGain* and *CapitalLoss* features are also associated with income. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eccd5a",
   "metadata": {},
   "source": [
    "### Step 3 - Explore the Feature Count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf6009",
   "metadata": {},
   "source": [
    "One downside to one-hot encoding is that it can significantly increase the features provided to *scikit-learn* machine learning algorithms. For example, the code below shows that the original nine features become 33 after one-hot encoding. Always remember the number of features that result from your data preparation. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfaabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfd714",
   "metadata": {},
   "source": [
    "### Step 4 - Preparing the Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d40a2",
   "metadata": {},
   "source": [
    "As with Lab 1, you need to encode the string values in the label before training a model. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b4c7b",
   "metadata": {},
   "source": [
    "### Step 5 - Train the Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425e352",
   "metadata": {},
   "source": [
    "The *scikit-learn* library was designed to enable repeating coding patterns regardless of the machine learning algorithm you use. For example, the *fit()* method is the same across the *DecisionTreeClassifier* and *RandomForestClassifer* classes. Type the following code into the blank code cell in your lab notebook and run it to produce the results.\n",
    "\n",
    "**NOTE** - You can adjust the *n_jobs* parameter if you have a more powerful laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e756c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43e368",
   "metadata": {},
   "source": [
    "### Step 6 - Get OOB Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d02e6",
   "metadata": {},
   "source": [
    "As discussed in lecture, think of OOB data as representing the unkownable future. Analyzing the predictive performance of a *RandomForestClassifier* in terms of OOB allows for estimating the quality of the model's future predictions. The first step is to build the predicted OOB labels. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a5472",
   "metadata": {},
   "source": [
    "### Step 7 - Analyzing the OOB Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3faf285",
   "metadata": {},
   "source": [
    "Using a *confusion matrix* to analyze OOB predictions gives you insights into how your *RandomForestClassifier* is performing. The confusion matrix allows you answer many questions about the nature of model predictions. As you will learn later, iterating over multiple model versions is common in a machine learning project. Analyzing the OOB of each model iteration is critical for crafting the most valuable models. Type the following code into the blank code cell in your lab notebook and run it to produce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e368f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your lab code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
